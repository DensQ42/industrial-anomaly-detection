from pydantic import BaseModel, Field
from typing import List, Dict, Optional, Any


class AnalysisResponse(BaseModel):
    """
    Response model for anomaly detection analysis API endpoints.

    This Pydantic model defines the standardized structure for API responses from
    anomaly detection services. It encapsulates all essential information about
    the analysis including the core prediction, confidence metrics, explanatory
    data, and metadata for traceability and debugging. The model ensures consistent
    API responses while providing comprehensive information for both automated
    systems and human interpretation.

    The response structure supports both machine-readable data (predictions, confidence
    scores, feature importances) and human-readable explanations, making it suitable
    for diverse use cases from automated monitoring systems to interactive dashboards
    and reporting tools.

    Attributes:
        prediction (int): Binary classification result where 0 indicates normal
            operation and 1 indicates detected anomaly. Validated to be 0 or 1.
        confidence (float): Model confidence score between 0.0 and 1.0, where
            higher values indicate greater certainty in the prediction.
        important_features (List[Dict[str, Any]]): List of dictionaries containing
            information about the most influential process variables for this
            prediction, typically including feature names, values, and importance scores.
        explanation (str): Human-readable explanation of the analysis results,
            typically generated by a language model to provide context and reasoning
            for the prediction.
        timestamp (str): ISO-formatted timestamp indicating when the analysis
            was performed, useful for auditing and temporal correlation.
        model_version (str): Version identifier of the machine learning model
            used for prediction, enabling version tracking and reproducibility.
        processing_time_ms (Optional[float]): Time taken to complete the analysis
            in milliseconds, useful for performance monitoring and optimization.
        input_rows_count (int): Number of data rows processed in the input,
            providing context about the analysis scope.
        simulation_run (int): Identifier for the simulation run from which the
            analyzed data originated, enabling traceability back to source data.
        target_sample (int): Specific time sample or data point that was the
            focus of the analysis, useful for temporal reference.
    """
    prediction: int = Field(..., ge=0, le=1, description='Binary prediction: 0=normal, 1=anomaly')
    confidence: float = Field(..., ge=0.0, le=1.0, description='Prediction confidence score')
    important_features: List[Dict[str, Any]] = Field(..., description='Most impactful process variables')
    explanation: str = Field(..., description='Human-readable explanation from LLM')
    timestamp: str = Field(..., description='Analysis timestamp')
    model_version: str = Field(default='1.0', description='Model version used')
    processing_time_ms: Optional[float] = Field(default=None, description='Processing time in milliseconds')
    input_rows_count: int = Field(..., description='Number of input data rows processed')
    simulation_run: int = Field(..., description='Simulation run identifier from data')
    target_sample: int = Field(..., description='Target time sample analyzed')


class HealthResponse(BaseModel):
    """
    Response model for API health check endpoints.

    This Pydantic model defines the structure for health monitoring responses,
    providing essential information about the service status and availability
    of critical components. Health checks are crucial for monitoring distributed
    systems, enabling load balancers, orchestration tools, and monitoring
    systems to make informed decisions about service routing and alerting.

    The model captures both overall service status and the availability of
    key dependencies (ML model and LLM service), allowing for granular
    health assessment and targeted troubleshooting when issues arise.

    Attributes:
        status (str): Overall service health status, typically values like
            'healthy', 'degraded', or 'unhealthy' indicating the general
            operational state of the service.
        timestamp (str): ISO-formatted timestamp of when the health check
            was performed, enabling temporal tracking of service availability
            and performance trends.
        model_loaded (bool): Indicates whether the machine learning model
            is successfully loaded and ready for inference operations.
            Critical for anomaly detection functionality.
        llm_available (bool): Indicates whether the Large Language Model
            service is accessible and responsive for generating explanations
            and human-readable analysis results.
    """
    status: str = Field(..., description='Service status')
    timestamp: str = Field(..., description='Health check timestamp')
    model_loaded: bool = Field(..., description='Whether ML model is loaded')
    llm_available: bool = Field(..., description='Whether LLM service is available')


class ModelInfo(BaseModel):
    """
    Information model for describing ML model configuration and requirements.

    This Pydantic model provides comprehensive metadata about the machine learning
    model and associated services used in the anomaly detection system. It serves
    as a configuration reference and documentation endpoint, helping users understand
    the model capabilities, input requirements, and system architecture.

    The model information is essential for API consumers to properly format their
    requests, understand system capabilities, and ensure compatibility with the
    expected data formats and feature engineering requirements.

    Attributes:
        model_type (str): Classification of the machine learning model being used
            (e.g., 'Random Forest', 'XGBoost', 'Isolation Forest'), providing
            insight into the underlying algorithm and its characteristics.
        features_count (int): Total number of input features expected by the model,
            including both original process variables and any engineered features
            such as rolling statistics, lags, or differences.
        llm_model (str): Identifier of the Large Language Model used for generating
            human-readable explanations and analysis interpretations (e.g., 'gpt-4',
            'claude-3', 'llama-2').
        training_data (str): Description of the dataset used for model training,
            including source, time period, conditions, and any relevant characteristics
            that affect model applicability and performance expectations.
        expected_csv_format (Dict[str, Any]): Detailed specification of the required
            CSV input format including column names, data types, expected ranges,
            required vs optional fields, and any preprocessing requirements.
    """
    model_type: str = Field(..., description='Type of ML model')
    features_count: int = Field(..., description='Number of input features')
    llm_model: str = Field(..., description='LLM model used for explanations')
    training_data: str = Field(..., description='Training dataset description')
    expected_csv_format: Dict[str, Any] = Field(..., description='Expected CSV format and requirements')


class CSVValidationResponse(BaseModel):
    """
    Response model for CSV file validation results.

    This Pydantic model encapsulates the results of validating uploaded CSV files
    against expected format requirements for anomaly detection analysis. It provides
    comprehensive feedback about data quality, format compliance, and structural
    characteristics to help users identify and correct issues before processing.

    The validation response distinguishes between critical errors that prevent
    processing and warnings that indicate potential issues but don't block analysis.
    It also provides metadata about the detected data structure to help users
    understand what was processed and verify expectations.

    Attributes:
        is_valid (bool): Overall validation status indicating whether the CSV
            meets all critical requirements for processing. True means the file
            can be processed, False indicates blocking errors exist.
        errors (List[str]): List of critical validation errors that prevent
            processing, such as missing required columns, invalid data types,
            or format violations that must be resolved.
        warnings (List[str]): List of non-blocking issues that may affect
            analysis quality or indicate potential problems, such as missing
            optional columns, unusual value ranges, or data quality concerns.
        data_shape (Optional[tuple]): Dimensions of the uploaded data as
            (number_of_rows, number_of_columns), providing quick insight into
            dataset size and helping verify expected data volume.
        detected_simulation_runs (Optional[List[int]]): List of unique simulation
            run identifiers found in the data, useful for understanding the
            scope of experiments included and planning analysis strategies.
        sample_range (Optional[Dict[str, int]]): Dictionary containing 'min' and
            'max' keys with the range of sample/time values, helping users
            understand the temporal span of their data.
    """
    is_valid: bool = Field(..., description='Whether CSV format is valid')
    errors: List[str] = Field(..., description='List of validation errors if any')
    warnings: List[str] = Field(..., description='List of warnings')
    data_shape: Optional[tuple] = Field(default=None, description='Shape of the data (rows, columns)')
    detected_simulation_runs: Optional[List[int]] = Field(default=None, description='Detected simulation runs')
    sample_range: Optional[Dict[str, int]] = Field(default=None, description='Min and max sample values')